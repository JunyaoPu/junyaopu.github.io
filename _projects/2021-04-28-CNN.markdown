---
layout: single
title:  "Design and Implementation of a Convolutional Neural Network Using
Tensor-Train Decomposition"
date:   2021-04-28 00:43:00 -0500
collection: projects
author_profile: true
toc: true
classes: wide
header:
    teaser: /assets/images/project_CNN.png
---

This was my master's project that introduced a new formulation of the convolutional layer in neural networks and a new training algorithm using Bayesian inference to address the issue of memory consumption in handling high-dimensional data. The proposed Bayesian TensorNet (BTN) provides a compressed network size and simplifies the computation in the neural network forward process.

# Introduction
In recent years, artificial neural networks (ANNs) have shown great success in various fields, but the use of expensive hardware and long training and inference times limit their application on cheap or portable devices. One solution to this problem is the tensor-train decomposition method, which decomposes a high-order tensor into lower-order tensor cores with fast tensor operations. The method has been used in the past to represent fully connected layers and convolutional layers, but our proposed approach is a more general tensor-train formulation of the convolutional layer that can handle tensors of any dimension and is not limited to matrix-matrix multiplication. This will help to reduce the overall size of the ANN and speed up training and inference time.

# Contribution
My new convolutional layer is based on the tensor-train decomposition, which breaks down high-dimensional tensors into lower-dimensional cores. Our novel approach is more flexible than previous methods as it uses partial mode-n correlation instead of matrix-matrix multiplication, resulting in more efficient computation and smaller network size. Also, we trained our network using a Bayesian algorithm with sequential Monte Carlo method, an alternative to backpropagation algorithm, for improved performance. My research advances the field by introducing a more efficient and effective tensor-train convolutional layer and the use of a Bayesian training algorithm.

# Project Details
For more detailed information, please refer to my master's thesis available online on mspace <a href="https://mspace.lib.umanitoba.ca/handle/1993/36582">Design and implementation of a convolutional neural network using tensor-train decomposition</a>

# Sample dataset
In my graduate project, I used a plant dataset from <a href="https://www.acs.uwinnipeg.ca/terrabyte/">TerraByte Lab</a> for training and testing a plant classification problem using a convolutional neural network. The dataset includes a large number of images with labels for various plants such as canola, soybean, wheat, and foxtail. These images were used to train and test our novel tensor-train formulation of the convolutional neural network. Our approach aims to address the issue of memory consumption in handling high-dimensional data and improve the efficiency of the neural network by reducing its size and simplifying the computation in the forward process.
<style>
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  min-width: 30%;
  max-width: 50%;
  width: 50vw;
}
</style>
<img class="center" src="/assets/images/project_CNN_data.png" alt="Sample of my training dataset."> 

Our novel tensor-train formulation of the convolutional layer in neural networks significantly reduces the size of the network by 20x, making it more efficient for memory-constrained and portable devices and faster to train and infer.



